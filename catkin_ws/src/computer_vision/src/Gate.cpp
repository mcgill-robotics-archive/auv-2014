/**
 * This object is used to detect the gate object.
 *
 * @author Jean-Sebastien Dery
 * @author Renaud Dagenais
 * @author Haris Haidary
 * @author Frederic Lafrance
 */

#include "Gate.h"

#define USE_CV_WINDOWS 1

const std::string COLOR_THRESH_WINDOW = "color_thresh_window";
const std::string TRACKBARS_WINDOW = "trackbars_window";

float centimetersPerPixel;

cv::Point centerOfCurrentFrame;

/**
 * Constructor.
 */
Gate::Gate() {
	ROS_INFO("%s", "The Gate object has been created.");

#ifdef USE_CV_WINDOWS
	ROS_INFO("%s",
			"Creating the window that will be displaying the frame after the HSV threshold is applied.");
	cv::namedWindow(COLOR_THRESH_WINDOW, CV_WINDOW_KEEPRATIO);
	cv::namedWindow(TRACKBARS_WINDOW, CV_WINDOW_KEEPRATIO);

	cv::createTrackbar("end_hsv_hue_threshold", TRACKBARS_WINDOW, &end_hsv_hue_threshold, MAX_HSV_VALUE);
	cv::createTrackbar("start_hsv_value_threshold", TRACKBARS_WINDOW, &start_hsv_value_threshold, MAX_HSV_VALUE);
	cv::createTrackbar("end_hsv_value_threshold", TRACKBARS_WINDOW, &end_hsv_value_threshold, MAX_HSV_VALUE);
	cv::createTrackbar("gate_ratio_error", TRACKBARS_WINDOW, &gate_ratio_error, MAX_HSV_VALUE);
	cv::createTrackbar("max_number_points", TRACKBARS_WINDOW, &max_number_points, MAX_HSV_VALUE);
	cv::createTrackbar("polygon_approximation_threshold", TRACKBARS_WINDOW, &polygon_approximation_threshold, MAX_HSV_VALUE);
#endif
}

/**
 * Destructor.
 */
Gate::~Gate() {
#ifdef USE_CV_WINDOWS
	cv::destroyWindow(COLOR_THRESH_WINDOW);
#endif
}

/**
 * Applies the necessary filters to the current frame, checks if the door
 * object is present and, if it is, extracts the necessary information.
 * @param currentFrame Current camera frame
 * @return If the door is present, it returns a pointer to an ObjectData
 *  which contains the information gathered on the door. If the door is
 *  not present in the current frame, it returns the zero pointer (NULL).
 */
std::vector<computer_vision::VisibleObjectData*> Gate::retrieveObjectData(cv::Mat& currentFrame) {

	std::vector<computer_vision::VisibleObjectData*> messagesToReturn;
	m_isVisible = false;

	applyFilter(currentFrame);

	//ROS_INFO("%s", "The processing for the Gate object is completed. Now creating the ROS message.");

	if (m_isVisible) {
		computer_vision::VisibleObjectData* visibleObjectData = new computer_vision::VisibleObjectData();		

		// Return gathered data to caller
		visibleObjectData->object_type = visibleObjectData->DOOR;
		visibleObjectData->yaw_angle = m_yawAngle;
		visibleObjectData->pitch_angle = 0.0; //Pitch angle is not used anymore
		visibleObjectData->x_distance = m_xDistance;
		visibleObjectData->y_distance = m_yDistance;
		visibleObjectData->z_distance = m_zDistance;

		messagesToReturn.push_back(visibleObjectData);	
	} 

	return (messagesToReturn);
}

/**
 * Function that will apply filter on the image so we can detect the door.
 *
 * @param currentFrame The frame to which we need to apply the filters.
 */
void Gate::applyFilter(cv::Mat& currentFrame) {
	HSV_ENDING_FILTER_RANGE = cv::Scalar(end_hsv_hue_threshold, 255, end_hsv_value_threshold);
	HSV_STARTING_FILTER_RANGE = cv::Scalar(0, 0, start_hsv_value_threshold);

	std::vector<PoleCandidate> potentialMatchRectangles;

	// Ok so what I need to do is accept more rectangles and apply logic to filter them
	// no bounds for the maximum of points, and only filter for a percentage of the heigh relative to the image resolution.
	// also, the rectangles should be almost vertically aligned.

	//ROS_INFO("%s", "Applying filter to the current frame.");

	centerOfCurrentFrame.x = currentFrame.cols/2;
	centerOfCurrentFrame.y = currentFrame.rows/2;
	cv::circle(currentFrame, centerOfCurrentFrame, 5, MAUVE_BGRX, 2, 5);
	//ROS_INFO("%s", ("Width of image=" + boost::lexical_cast<std::string>(currentFrame.cols) + " pixels. Height of image="  + boost::lexical_cast<std::string>(currentFrame.rows) + " pixels.").c_str());

	// Converts the current frame to HSV in order to ease color filtering (with varying brightness).
	cv::Mat currentFrameInHSV = convertFromBGRXToHSV(currentFrame);

	// Apply a Gaussian Blur filter to regularise the pixels from the camera image.
	// This is done in a try to reduce the noise generated by the sensor of the camera.
	cv::GaussianBlur(currentFrameInHSV, currentFrameInHSV, cv::Size(KERNEL_SIZE, KERNEL_SIZE), 0, 0);

	// Finds all the contours in the image and store them in a vector containing vectors of points.
	std::vector<std::vector<cv::Point> > detectedContours = findContoursFromHSVFrame(currentFrameInHSV);

	// Goes through all the identified shapes for a first filtering.
	for (int rectangleID = 0; rectangleID < detectedContours.size(); rectangleID++) {
		// Gets the contour to analyse in this loop iteration.
		std::vector<cv::Point> contourToAnalyse = detectedContours.at(rectangleID);

		// Gets the number of points that define this contour.
		int numberOfPointsInContour = contourToAnalyse.size();

		// Finds a rotated rectangle that defines the contour of the object.
		cv::RotatedRect foundRectangle = cv::minAreaRect(cv::Mat(contourToAnalyse));

		// Determining the Width, Height and Ratio of the rotated rectangle.
		// Here by convention the height is the longest side of the rectangle.
		float width = (foundRectangle.size.width < foundRectangle.size.height) ? foundRectangle.size.width : foundRectangle.size.height;
		float height = (foundRectangle.size.width < foundRectangle.size.height) ? foundRectangle.size.height : foundRectangle.size.width;
		float heightWidthRatio = height / width;

		/* Calculate the angle of the rectangle. It is in interval [0, 180) and
		works as expected (i.e. rectangle on its side has angle 0, rectangle upright has
		angle 90) */
		cv::Point2f vertices[4];
		foundRectangle.points(vertices);
		cv::Point2f p = vertices[0], q = vertices[1];
		cv::Point2f diff = p - q;
		float distanceFirstPoints = sqrt(diff.x * diff.x + diff.y * diff.y);
		//Check whether the two points we have form a width or a height.
		if(std::abs(distanceFirstPoints - width) < std::abs(distanceFirstPoints - height)) {
			p = q;
			q = vertices[2];
		}

		float opp = std::abs(p.y - q.y); //Want positive opposite side value
		//Get signed adjacent value (it's the highest point minus the lowest point)
		float adj = p.x - q.x;
		if(q.y < p.y)
			adj = -adj;

		float rectangleAngle = atan(opp / adj) * 180.0 / 3.141592654;
		if(rectangleAngle < 0)
			rectangleAngle = 180 + rectangleAngle;

		float angleError = std::abs(rectangleAngle - DESIRED_ANGLE_OF_RECT);

		// First, make sure that our ratio is acceptably close to what we expect
		// Also, we need at least 4 points in our contour.
		if (	heightWidthRatio > MIN_GATE_RATIO && 
			numberOfPointsInContour >= 4 &&
			angleError < ANGLE_RECT_ERROR	) {

			float approximateDistanceWithObject = (FOCAL_LENGTH * DOOR_REAL_HEIGHT * currentFrame.size().height) / 
							(height * CAMERA_SENSOR_HEIGHT);

			// Add the rectangle that is a potential match for the orange cylinders of the gate.
			PoleCandidate found = {height, width, rectangleAngle, approximateDistanceWithObject, foundRectangle.center};
			potentialMatchRectangles.push_back(found);
			drawPointsOfContour(currentFrame, contourToAnalyse, GREEN_BGRX);

			// Draws text containing the dimensions on each rectangles.
			
			putText(currentFrame, "Distance=" + boost::lexical_cast<std::string>(approximateDistanceWithObject),
					cv::Point(vertices[0].x, vertices[0].y + 30),
					cv::FONT_HERSHEY_COMPLEX_SMALL, 0.4, WHITE_BGRX, 1,
					CV_AA);
			
		} else {
			std::cout << "[DEBUG] Rejected rectangle: Points in contour: " << numberOfPointsInContour << 
					"  Ratio error: " << heightWidthRatio << "  Angle: " << rectangleAngle << std::endl;
			drawPointsOfContour(currentFrame, contourToAnalyse, RED_BGRX);
		}

		// Goes through each vertex and connects them to write the edges of the rectangle.
		for (int i = 0; i < 4; ++i) {
			cv::line(currentFrame, vertices[i], vertices[(i + 1) % 4], BLUE_BGRX, 1, CV_AA);
		}

		putText(currentFrame, "Width=" + boost::lexical_cast<std::string>(width),
				cv::Point(vertices[0].x, vertices[0].y),
				cv::FONT_HERSHEY_COMPLEX_SMALL, 0.4, WHITE_BGRX, 1,
				CV_AA);
		putText(currentFrame, "Height=" + boost::lexical_cast<std::string>(height),
				cv::Point(vertices[0].x, vertices[0].y + 10),
				cv::FONT_HERSHEY_COMPLEX_SMALL, 0.4, WHITE_BGRX, 1,
				CV_AA);
		putText(currentFrame, "Angle=" + boost::lexical_cast<std::string>(rectangleAngle),
				cv::Point(vertices[0].x, vertices[0].y + 20),
				cv::FONT_HERSHEY_COMPLEX_SMALL, 0.4, WHITE_BGRX, 1,
				CV_AA);

	}

	int numberOfPotentialMatch = potentialMatchRectangles.size();
	//  Here I assume that the two rectangles that I have are the orange cylinders of the gate.
	if (numberOfPotentialMatch == 2) {
		m_isVisible = true;
		PoleCandidate p1 = potentialMatchRectangles[0];
		PoleCandidate p2 = potentialMatchRectangles[1];

		PoleCandidate& closest = (p1.dist < p2.dist) ? p1 : p2;
		PoleCandidate& farthest = (p2.dist < p1.dist) ? p2 : p1;

		//Calculate the yaw angle by triangle-solving
		float distDiff = std::abs(p1.dist - p2.dist);
		float mPerPxAtClosestPole = DOOR_REAL_HEIGHT / closest.h;
		float perceivedGateWidth = std::abs(p1.center.x - p2.center.x) * mPerPxAtClosestPole;
		
		std::cout << "[DEBUG] m/px closest: " << mPerPxAtClosestPole << " perceived: " << perceivedGateWidth << std::endl;

		//Solve for theta in distDiff² = GATE_SZ² + perceived² - 2 x GATE_SZ x perceived x cos(theta) (law of cosines)
		const float GATE_WIDTH_SQR = DISTANCE_BETWEEN_ORANGE_CYLINDER * DISTANCE_BETWEEN_ORANGE_CYLINDER;
		const float PERCEIVED_SQR = perceivedGateWidth * perceivedGateWidth;
		const float DIST_DIFF_SQR = distDiff * distDiff;
		float cosTheta = (GATE_WIDTH_SQR + PERCEIVED_SQR - DIST_DIFF_SQR) / 
			(2.0 * DISTANCE_BETWEEN_ORANGE_CYLINDER * perceivedGateWidth);

		m_yawAngle = acos(cosTheta) * 180.0 / 3.141592654;

		//Get the center point of the gate in the x,y plane
		float mPerPxAtFarthestPole = DOOR_REAL_HEIGHT / farthest.h;
		float perceivedFarGateWidth = std::abs(p1.center.x - p2.center.x) * mPerPxAtFarthestPole;

		//TODO Fred: This doesn't actually work 
		float closePoleOffest = (closest.center.x - centerOfCurrentFrame.x) * mPerPxAtClosestPole;
		float sign = (farthest.center.x < closest.center.x) ? -1.0 : 1.0;
		m_yDistance = closePoleOffest + sign * perceivedFarGateWidth / 2.0;

		float smallestDistance = (p1.dist < p2.dist) ? p1.dist : p2.dist;
		m_xDistance = smallestDistance + (distDiff / 2.0);
		

		float estimatedMPerPxAtCenter = mPerPxAtClosestPole + 
				((mPerPxAtClosestPole - mPerPxAtFarthestPole) / 2.0);


		//Draw the point on-screen
		cv::Point centerPoint;
		centerPoint.x = (p1.center.x + p2.center.x)/2;
		centerPoint.y = (p1.center.y + p2.center.y)/2;

		m_zDistance = (centerPoint.y - centerOfCurrentFrame.y) * estimatedMPerPxAtCenter;

		cv::circle(currentFrame, centerPoint, 30, GREEN_BGRX, 2, 5);
		cv::line(currentFrame, p1.center, p2.center, WHITE_BGRX, 1, CV_AA); 

		std::cout << "[DEBUG] Door found: <" << m_xDistance << "," << m_yDistance << "," << m_zDistance << "> angle " << 
				m_yawAngle << std::endl;
	}
}

/**
 * Finds all contours (based on a HSV range) from an HSV frame and returns the cloud of points determining the contour.
 *
 * @param frameInHSV The frame in HSV color space.
 * @return The std::vector of std::vector of points containing the clouds of all contours in the image.
 */
std::vector<std::vector<cv::Point> > Gate::findContoursFromHSVFrame(const cv::Mat& frameInHSV) {
	// Creates the Mat object that will contain the filtered image (inRange HSV).
	cv::Mat inRangeHSVFrame;
	// Generates a new Mat object that only contains a certain range of HSV values.
	// Don't forget that we are not using BGRX, but the HSV color space.
	cv::inRange(frameInHSV, HSV_STARTING_FILTER_RANGE, HSV_ENDING_FILTER_RANGE, inRangeHSVFrame);

#ifdef USE_CV_WINDOWS
	cv::imshow(COLOR_THRESH_WINDOW, inRangeHSVFrame);
#endif

	// Finds the contours in the images.
	cv::Mat inRangeFrame = inRangeHSVFrame.clone();
	// So this vector will contain vectors of points that will form shapes in the image.
	std::vector<std::vector<cv::Point> > detectedContours;
	cv::findContours(inRangeHSVFrame, detectedContours, CV_RETR_CCOMP,
			CV_CHAIN_APPROX_SIMPLE);

	return (detectedContours);
}

/**
 * Draws the points defining a contour.
 *
 * @param frame The cv::Mat object on which the points will be drawn.
 * @param contour The vector containing the points to be drawn.
 */
void Gate::drawPointsOfContour(cv::Mat& frame, std::vector<cv::Point> contour, cv::Scalar COLOR) {
	// Draw each single point that forms the polygon.
	for (int j = 0; j < contour.size(); j++) {
		cv::Point singlePoint = contour.at(j);
		rectangle(frame, singlePoint, singlePoint, COLOR, 8, 8);
	}
}
