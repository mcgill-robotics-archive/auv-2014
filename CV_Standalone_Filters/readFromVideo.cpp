#include "opencv2/highgui/highgui.hpp"
#include "opencv/cv.h"
#include "iostream"

// Defines the different constants used:
const int CANNY_RATIO = 3;
const int CANNY_LOW_THRESHOLD = 200;
const int KERNEL_SIZE = 3;

// Defines the basic colors used in the BGRX color space.
const cv::Scalar GREEN_BGRX = cv::Scalar(0, 255, 0);
const cv::Scalar BLUE_BGRX = cv::Scalar(255, 0, 0);
const cv::Scalar RED_BGRX = cv::Scalar(0, 0, 255);
const cv::Scalar WHITE_BGRX = cv::Scalar(255, 255, 255);
const cv::Scalar MAUVE_BGRX = cv::Scalar(212, 115, 212);

// Defines the different windows used.
const std::string ORIGINAL_WINDOW = "ORIGINAL_WINDOW";
const std::string CONTOURED_WINDOW = "CONTOURED_WINDOW";
const std::string FILTERED_WINDOW = "FILTERED_WINDOW";

void executeVideo(cv::VideoCapture cap);
void applyFilter(const cv::Mat& hsvCurrentFrame, cv::Mat& currentFrame);

/**
 * Goes through each frames of the video and loops back to the begining on the last frame.
*/
void executeVideo(cv::VideoCapture cap) {
	while (1) {
		cv::Mat currentFrame;
		cv::Mat hsvCurrentFrame;

		bool readCurrentFrame = cap.read(currentFrame);
		if (!readCurrentFrame) {
			std::cout << "[INFO] Looping back to the first frame." << std::endl;
			cap.set(CV_CAP_PROP_POS_FRAMES, 35);
			readCurrentFrame = cap.read(currentFrame);
		}

		// Converts the taken frame to HSV.
		cv::cvtColor(currentFrame, hsvCurrentFrame, CV_BGR2HSV);
		std::cout << "Type of hsvCurrentFrame= " << hsvCurrentFrame.type() << std::endl;

		applyFilter(hsvCurrentFrame, currentFrame);

		// Manages the frquency at which the frames are being updated. And closes the windows whenever ESC is pressed.
		if (cv::waitKey(150) == 27) {
			std::cout << "[WARNING] The user has pressed ESC. Terminating the process" << std::endl;
			exit(EXIT_SUCCESS);
		}
	}
}

/**
 * Function that will apply filter on the image so we can detect the door.
*/
void applyFilter(const cv::Mat& hsvCurrentFrame, cv::Mat& currentFrame) {

	std::cout << "[INFO] Applying filter to the current frame" << std::endl;

	// Creates the Mat object that will contain the filtered image.
	cv::Mat filteredFrame;
	cv::Mat frameOnlyWithContours = cv::Mat(hsvCurrentFrame.rows, hsvCurrentFrame.cols, CV_8UC3);
	frameOnlyWithContours.setTo(WHITE_BGRX);

	// Apply a Gaussian Blur filter to regularise the pixels from the camera image.
	// This is done in a try to reduce the noise generated by the sensor of the camera.
	cv::GaussianBlur(hsvCurrentFrame, hsvCurrentFrame, cv::Size(KERNEL_SIZE, KERNEL_SIZE), 0, 0);

	// Generates a new Mat object that only contains a certain range of HSV values.
	// Don't forget that we are not using BGRX, but the HSV color space.
	cv::inRange(hsvCurrentFrame, cv::Scalar(0, 0, 0), cv::Scalar(20, 255, 220), filteredFrame);

	cv::Mat inRangeFrame = filteredFrame.clone();

	// So this vector will contain vectors of points that will form shapes in the image.
	std::vector<std::vector<cv::Point> > detectedContours;
	cv::findContours(filteredFrame, detectedContours, CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE);

	for (int i = 0 ; i < detectedContours.size() ; i++) {
		// Gets the contour to analyse in this loop iteration.
		std::vector<cv::Point> contourToAnalyse = detectedContours.at(i);
		// Approximates a polygonal curve(s) with the specified precision.
		std::vector<cv::Point> contourAfterPolygonApproximation;
		approxPolyDP(contourToAnalyse, contourAfterPolygonApproximation, 3, true);

		detectedContours.at(i) = contourAfterPolygonApproximation;

		// Gets the number of points that define this contour.
		int numberOfPointsInContour = contourAfterPolygonApproximation.size();

		// Displays only the contours that have a number of points in the specified range.
		if (numberOfPointsInContour >= 4 && numberOfPointsInContour <= 50/* && isContourConvex(cv::Mat(contourAfterPolygonApproximation))*/) {
			cv::Rect boundingRectangle = boundingRect(contourAfterPolygonApproximation);
			rectangle(currentFrame, boundingRectangle.tl(), boundingRectangle.br(), BLUE_BGRX, 2, 8, 0);

			drawContours(currentFrame, detectedContours, i, GREEN_BGRX, 4, 8);
			drawContours(frameOnlyWithContours, detectedContours, i, GREEN_BGRX, 4, 8);

			std::cout << "[DEBUG] Number of points in this contour= " << numberOfPointsInContour << std::endl;

			int xCenter = 0;
			int yCenter = 0;

			// Draw each single point that forms the polygon.
			for (int j = 0 ; j < numberOfPointsInContour ; j++ ) {
				cv::Point singlePoint = detectedContours.at(i).at(j);

				xCenter += singlePoint.x;
				yCenter += singlePoint.y;

				rectangle(currentFrame, singlePoint, singlePoint, RED_BGRX, 8, 8);
			}

			// Finding the center point of the countour and drawing it as a circle.
			xCenter = xCenter/numberOfPointsInContour;
			yCenter = yCenter/numberOfPointsInContour;
			cv::Point center = cv::Point(xCenter, yCenter);
			circle(currentFrame, center, 5, MAUVE_BGRX, 3, 8);
		}

		//if (numberOfContours >= 50 && numberOfContours <= 300) {
			/*std::cout << "[INFO] Detected a rectangle in the image. Coordinate:" << std::endl;
			std::vector<cv::Point> detectedRectangle = detectedContours.at(i);
			std::cout << "[INFO] P1(" << detectedRectangle.at(0).x << ";" << detectedRectangle.at(0).y << ")";
			std::cout << " P2(" << detectedRectangle.at(1).x << ";" << detectedRectangle.at(1).y << ")";
			std::cout << " P3(" << detectedRectangle.at(2).x << ";" << detectedRectangle.at(2).y << ")";
			std::cout << " P4(" << detectedRectangle.at(3).x << ";" << detectedRectangle.at(3).y << ")" << std::endl;*/
			//drawContours(currentFrame, detectedContours, i, contourColor, 8, 8);
			//drawContours(frameOnlyWithContours, detectedContours, i, contourColor, 8, 8);
		//}
	}

	// Finds the contour of the image before trying to find the lines in the image.
	//cv::Canny(filteredFrame, filteredFrame, cannyLowThreshold, (cannyLowThreshold*cannyRatio), kernelSize);

	// OpenCV cannot display HSV images properly since it interprets the image as RGB.
	cv::imshow(FILTERED_WINDOW, inRangeFrame);
	cv::imshow(CONTOURED_WINDOW, frameOnlyWithContours);
	// Updates the frame on the window.
	cv::imshow(ORIGINAL_WINDOW, currentFrame);
}

/**
 * Main function that does the preamble before the video's execution.
*/
int main(int argc, char* argv[]) {

	int windowWidth = 500;
	int windowHeight = 500;

	// Making sure that we have the video provided.
	if (argc != 2) {
		std::cout << "[ERROR] The number of parameters is not correct." << std::endl;
	} else {
		std::cout << "[INFO] The input provided is \"" << argv[1] << "\"" << std::endl;
	}
	
	// Opens the video file given in the parametersCV_CAP_PROP_POS_MSEC.
	cv::VideoCapture cap(argv[1]);

	// Verifies that the video was open successfuly.
	if (!cap.isOpened()) {
		std::cout << "[ERROR] Cannot open the video file" << std::endl;
		return (-1);
	}

	// Gets the video's FPS
	double videoFPS = cap.get(CV_CAP_PROP_FPS);
	int frameWidth = cap.get(CV_CAP_PROP_FRAME_WIDTH);
	int frameHeight = cap.get(CV_CAP_PROP_FRAME_HEIGHT);
	cap.set(CV_CAP_PROP_POS_FRAMES, 35);

	std::cout << "[INFO] FPS=" << videoFPS << std::endl;
	std::cout << "[INFO] Frame width=" << frameWidth << std::endl;
	std::cout << "[INFO] Frame height=" << frameHeight << std::endl;

	// Creates the windows to be used for testing.
	cv::namedWindow(ORIGINAL_WINDOW, CV_WINDOW_KEEPRATIO);
	cv::namedWindow(CONTOURED_WINDOW, CV_WINDOW_KEEPRATIO);
	cv::namedWindow(FILTERED_WINDOW, CV_WINDOW_KEEPRATIO);

	// Sets the size of the windows to be used for testing.
	cv::moveWindow(ORIGINAL_WINDOW, 100, 30);
	cv::moveWindow(CONTOURED_WINDOW, 100, 400);
	cv::moveWindow(FILTERED_WINDOW, 550, 30);

	executeVideo(cap);

	cv::destroyAllWindows();
}
